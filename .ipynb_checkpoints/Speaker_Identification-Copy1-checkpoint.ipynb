{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from feature_ext import YaafeMFCC\n",
    "import h5py\n",
    "from random import shuffle\n",
    "import keras\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "def data_generator_classification(npy_files: list, batch_size: int, steps: int, num_classes: int,\n",
    "                                  mode: str='train', model: str='CNN'):\n",
    "    \"\"\"\n",
    "    Generator for generating training and validation data for the speaker classification training.\n",
    "    \n",
    "    args:\n",
    "        npy_files: list of lists. Each sublist consist of two elements. The first is the path to the npy file \n",
    "                    with the features and the secon with path to the targets\n",
    "        batch_size: int with batch size\n",
    "        steps: int meaning number of batches per epoch\n",
    "        mode: string indicating whether this generator is used for training or validation data\n",
    "        model: string holding type of model we are training (only CNN or LSTM) for adding channels in case of CNN\n",
    "        \n",
    "    yields:\n",
    "        (features, targets): tuple with feature (shape: LSTM -> batch_size, W, H; CNN -> batch_size, W, H, 1) \n",
    "                            and target batch \n",
    "    \"\"\"\n",
    "    \n",
    "    # load sample file to determine shapes of the data\n",
    "    f = np.load(npy_files[0][0])\n",
    "    f_N, f_W, f_H = f.shape\n",
    "    \n",
    "    idxs = np.arange(len(npy_files))\n",
    "    n = int(batch_size/f_N)\n",
    "    assert mode=='train' or mode=='val'\n",
    "    \n",
    "    if mode == 'train':\n",
    "        while True:\n",
    "            \n",
    "            # get files and retrieve data\n",
    "            f_idxs = np.random.choice(idxs, size=n)\n",
    "            features = np.zeros((batch_size, f_W, f_H))\n",
    "            targets = np.zeros(batch_size)\n",
    "            for i in range(n):\n",
    "                file = npy_files[f_idxs[i]]\n",
    "                dfile = file[0]\n",
    "                tfile = file[1]\n",
    "                samples = np.load(dfile)\n",
    "                sample_targets = np.load(tfile)\n",
    "                features[i*f_N:(i+1)*f_N] = samples\n",
    "                targets[i*f_N:(i+1)*f_N] = sample_targets\n",
    "\n",
    "            # transform targets to categrorical\n",
    "            targets = to_categorical(targets, num_classes)\n",
    "            \n",
    "            # if CNN is trained insert channel\n",
    "            if model == 'CNN':\n",
    "                B, W, H = features.shape\n",
    "                if K.image_data_format() == 'channels_last':\n",
    "                    features = np.reshape(features, (B, W, H, 1))\n",
    "                else:\n",
    "                    features = np.reshape(features, (B, 1, W, H))\n",
    "\n",
    "            assert features.shape[0] == batch_size\n",
    "\n",
    "            yield (features, targets)\n",
    "        \n",
    "    # for val mode we dont need to draw random files, but just loop over the data\n",
    "    if mode == 'val':\n",
    "        while True:\n",
    "            \n",
    "            # get files and retrieve data\n",
    "            for j in range(steps):\n",
    "                features = np.zeros((batch_size, f_W, f_H))\n",
    "                targets = np.zeros(batch_size)\n",
    "                for i in range(n):\n",
    "                    file = npy_files[j+i]\n",
    "                    dfile = file[0]\n",
    "                    tfile = file[1]\n",
    "                    samples = np.load(dfile)\n",
    "                    sample_targets = np.load(tfile)\n",
    "                    features[i*f_N:(i+1)*f_N] = samples\n",
    "                    targets[i*f_N:(i+1)*f_N] = sample_targets\n",
    "\n",
    "                # transform targets to categrorical \n",
    "                targets = to_categorical(targets, num_classes)\n",
    "\n",
    "                # if CNN is trained insert channel\n",
    "                if model == 'CNN':\n",
    "                    B, W, H = features.shape\n",
    "                    if K.image_data_format() == 'channels_last':\n",
    "                        features = np.reshape(features, (B, W, H, 1))\n",
    "                    else:\n",
    "                        features = np.reshape(features, (B, 1, W, H))\n",
    "\n",
    "                assert features.shape[0] == batch_size\n",
    "\n",
    "                yield (features, targets)\n",
    "                \n",
    "\n",
    "def data_generator_identification(npy_files, batch_size, steps, cache_size=2, mode='train', model='CNN'):\n",
    "    \"\"\"\n",
    "    Generator for generating training and validation data for the speaker identification training.\n",
    "    \n",
    "    args:\n",
    "        npy_files: list of lists. Each sublist consist of two elements. The first is the path to the npy file \n",
    "                    with the features and the secon with path to the targets\n",
    "        batch_size: int with batch size\n",
    "        steps: int meaning number of batches per epoch\n",
    "        mode: string indicating whether this generator is used for training or validation data\n",
    "        model: string holding type of model we are training (only CNN or LSTM) for adding channels in case of CNN\n",
    "        \n",
    "    yields:\n",
    "        (features, targets): tuple with feature (shape: LSTM -> batch_size, W, H; CNN -> batch_size, W, H, 1) \n",
    "                            and target batch \n",
    "    \"\"\"\n",
    "    \n",
    "    # load sample file to determine shapes of the data\n",
    "    f = np.load(npy_files[0][0])\n",
    "    f_N, f_W, f_H = f.shape\n",
    "    \n",
    "    idxs = np.arange(len(npy_files))\n",
    "    n = int(batch_size/f_N)\n",
    "        \n",
    "    # get labels\n",
    "    labels = []\n",
    "    for file in npy_files:\n",
    "        targets = np.load(file[1])\n",
    "        labels = list(np.unique(labels + list(np.unique(targets))))\n",
    "    labels = [int(i) for i in labels]\n",
    "    \n",
    "    # build positive sample cache\n",
    "    cache_pos = dict()\n",
    "    for i in labels:\n",
    "        cache_pos[i] = []\n",
    "\n",
    "    cache_not_full = True\n",
    "    while cache_not_full:\n",
    "\n",
    "        f_idxs = np.random.choice(idxs, size=n)\n",
    "\n",
    "        for i in range(n):\n",
    "            file = npy_files[f_idxs[i]]\n",
    "            dfile = file[0]\n",
    "            tfile = file[1]\n",
    "            sample_targets = np.load(tfile)\n",
    "            samples = np.load(dfile)\n",
    "            for j in labels:\n",
    "                if len(cache_pos[j]) < cache_size:\n",
    "                    pos_mask = sample_targets == j\n",
    "                    if any(pos_mask):\n",
    "                        cache_pos[j] += list(samples[pos_mask])\n",
    "\n",
    "        full = []\n",
    "        for i in labels:\n",
    "            if len(cache_pos[i]) >= cache_size:\n",
    "                full.append(True)\n",
    "            else:\n",
    "                full.append(False)\n",
    "        if all(full):\n",
    "            cache_not_full = False\n",
    "            print('Positive samples cache full!')\n",
    "    \n",
    "    if mode == 'train':\n",
    "\n",
    "        while True:\n",
    "            f_idxs = np.random.choice(idxs, size=n)\n",
    "            features = np.zeros((batch_size, f_W, f_H))\n",
    "            targets = np.zeros(batch_size)\n",
    "            for i in range(n):\n",
    "                file = npy_files[f_idxs[i]]\n",
    "                dfile = file[0]\n",
    "                tfile = file[1]\n",
    "                samples = np.load(dfile)\n",
    "                sample_targets = np.load(tfile)\n",
    "                features[i*f_N:(i+1)*f_N] = samples\n",
    "                targets[i*f_N:(i+1)*f_N] = sample_targets\n",
    "\n",
    "            # get postive and negative samples\n",
    "            pos_samples = []\n",
    "            neg_samples = []\n",
    "            for i in range(len(targets)):\n",
    "                targ = int(targets[i])\n",
    "                idx_pos = np.random.choice(range(len(cache_pos[targ])))\n",
    "                neg_targets_mask = targets != targets[i]\n",
    "                neg_targets_masked = targets[neg_targets_mask]\n",
    "                neg_idx = np.random.choice(np.arange(len(targets[neg_targets_mask])))\n",
    "                pos_samples.append([cache_pos[targ][idx_pos]])\n",
    "                neg_samples.append([features[neg_targets_mask][neg_idx]])\n",
    "                cache_pos[targ][idx_pos] = features[i]\n",
    "            pos_samples = np.concatenate(pos_samples, axis=0)\n",
    "            neg_samples = np.concatenate(neg_samples, axis=0)\n",
    "            \n",
    "            features = np.concatenate([features, pos_samples, neg_samples], axis=0)\n",
    "#             targets = np.zeros(features.shape)\n",
    "            \n",
    "            if model == 'CNN':\n",
    "                B, W, H = features.shape\n",
    "                features = np.reshape(features, (B, W, H, 1))\n",
    "                \n",
    "            assert features.shape[0] == 3*batch_size\n",
    "\n",
    "            yield features\n",
    "        \n",
    "    if mode == 'val':\n",
    "        \n",
    "        while True:\n",
    "            \n",
    "            for j in range(steps):\n",
    "                features = np.zeros((batch_size, f_W, f_H))\n",
    "                targets = np.zeros(batch_size)\n",
    "                for i in range(n):\n",
    "                    file = npy_files[j+i]\n",
    "                    dfile = file[0]\n",
    "                    tfile = file[1]\n",
    "                    samples = np.load(dfile)\n",
    "                    sample_targets = np.load(tfile)\n",
    "                    features[i*f_N:(i+1)*f_N] = samples\n",
    "                    targets[i*f_N:(i+1)*f_N] = sample_targets\n",
    "\n",
    "                # get postive and negative samples\n",
    "                pos_samples = []\n",
    "                neg_samples = []\n",
    "                for i in range(len(targets)):\n",
    "                    targ = int(targets[i])\n",
    "                    idx_pos = np.random.choice(range(len(cache_pos[targ])))\n",
    "                    neg_targets_mask = targets != targets[i]\n",
    "                    neg_targets_masked = targets[neg_targets_mask]\n",
    "                    neg_idx = np.random.choice(np.arange(len(targets[neg_targets_mask])))\n",
    "                    pos_samples.append([cache_pos[targ][idx_pos]])\n",
    "                    neg_samples.append([features[neg_targets_mask][neg_idx]])\n",
    "                    cache_pos[targ][idx_pos] = features[i]\n",
    "                pos_samples = np.concatenate(pos_samples, axis=0)\n",
    "                neg_samples = np.concatenate(neg_samples, axis=0)\n",
    "\n",
    "                features = np.concatenate([features, pos_samples, neg_samples], axis=0)\n",
    "#                 targets = np.zeros(features.shape)\n",
    "\n",
    "                if model == 'CNN':\n",
    "                    B, W, H = features.shape\n",
    "                    features = np.reshape(features, (B, W, H, 1))\n",
    "\n",
    "                assert features.shape[0] == 3*batch_size\n",
    "\n",
    "                yield features\n",
    "                \n",
    "def data_loader_model_wrapper_classification(data_loader, state_shape):\n",
    "    \"\"\"\n",
    "    Interface between data loader and model\n",
    "    \n",
    "    args:\n",
    "        \n",
    "    returns:\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    while True:\n",
    "        features, targets = data_loader.__next__()\n",
    "        N, W, H = features.shape\n",
    "        W_pad = (W % 16 > 0)*(16 - W % 16)\n",
    "        H_pad = (H % 16 > 0)*(16 - H % 16)\n",
    "        features = np.pad(features, ((0,0),(0,W_pad),(0,H_pad)), 'constant', constant_values=((0,0),(0,0),(0,0)))\n",
    "        N, W, H = features.shape\n",
    "        input_dict = {\n",
    "            'x': np.reshape(features, (N, W*H)),\n",
    "            'y': targets,\n",
    "            'state': np.zeros(state_shape)\n",
    "        }\n",
    "        yield input_dict\n",
    "        \n",
    "def data_loader_model_wrapper_identification(data_loader, state_shape):\n",
    "    \"\"\"\n",
    "    Interface between data loader and model\n",
    "    \n",
    "    args:\n",
    "        \n",
    "    returns:\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    while True:\n",
    "        features = data_loader.__next__()\n",
    "        N, W, H = features.shape\n",
    "        W_pad = (W % 16 > 0)*(16 - W % 16)\n",
    "        H_pad = (H % 16 > 0)*(16 - H % 16)\n",
    "        features = np.pad(features, ((0,0),(0,W_pad),(0,H_pad)), 'constant', constant_values=((0,0),(0,0),(0,0)))\n",
    "        N, W, H = features.shape\n",
    "        input_dict = {\n",
    "            'x': np.reshape(features, (N, W*H)),\n",
    "            'state': np.zeros(state_shape)\n",
    "        }\n",
    "        yield input_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from established.utils.helper_functions import get_all_file_names\n",
    "from established.utils.data_loader import data_generator_classification\n",
    "from established.utils.data_loader import data_generator_identification\n",
    "from established.utils.data_loader import data_loader_model_wrapper_classification\n",
    "from established.utils.data_loader import data_loader_model_wrapper_identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If true: train classification, else: identification\n",
    "classification = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['established/config.ini']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse config\n",
    "config_file = 'established/config.ini'\n",
    "config = configparser.ConfigParser()\n",
    "config.read(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load paths of data files\n",
    "if classification:\n",
    "    train_files, val_files = get_all_file_names(config['DATA']['data_root'])\n",
    "else:\n",
    "    train_files, val_files = get_all_file_names(config['DATA']['data_root'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "batch_size = int(config['TRAINING']['batch_size'])\n",
    "samples_per_file = np.load(train_files[0][0]).shape[0]\n",
    "steps_per_epoch_train = int(len(train_files)*samples_per_file/batch_size)\n",
    "steps_per_epoch_val = int(len(val_files)*samples_per_file/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if classification:\n",
    "    # get data loader\n",
    "    train_gen = data_generator_classification(train_files, batch_size, steps_per_epoch_train, \n",
    "                                              int(config['DATA']['num_classes']),\n",
    "                                              mode='train', model='LSTM')\n",
    "    val_gen = data_generator_classification(val_files, batch_size, steps_per_epoch_val, \n",
    "                                            int(config['DATA']['num_classes']), \n",
    "                                            mode='val', model='LSTM')\n",
    "\n",
    "    # data loader wrapper -> reshape inputs, add state initialzation and pad time and dimension to \n",
    "    # multiple of 16\n",
    "    train_gen_wrap = data_loader_model_wrapper_classification(train_gen, [batch_size, \n",
    "                                                                     int(config['TRAINING']['encoding_dim'])])\n",
    "    val_gen_wrap = data_loader_model_wrapper_classification(train_gen, [batch_size, \n",
    "                                                                     int(config['TRAINING']['encoding_dim'])])\n",
    "else:\n",
    "    # get data loader\n",
    "    train_gen = data_generator_identification(train_files, batch_size, steps_per_epoch_train, mode='train', model='LSTM')\n",
    "    val_gen = data_generator_identification(val_files, batch_size, steps_per_epoch_val, mode='val', model='LSTM')\n",
    "\n",
    "    # data loader wrapper -> reshape inputs, add state initialzation and pad time and dimension to \n",
    "    # multiple of 16\n",
    "    train_gen_wrap = data_loader_model_wrapper_identification(train_gen, [batch_size, \n",
    "                                                                     int(config['TRAINING']['encoding_dim'])])\n",
    "    val_gen_wrap = data_loader_model_wrapper_identification(train_gen, [batch_size, \n",
    "                                                                     int(config['TRAINING']['encoding_dim'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset default graph in case graph has already been defined\n",
    "tf.reset_default_graph()\n",
    "\n",
    "if classification:\n",
    "    input_dict, output_dict = get_simple_LSTM_classification(int(config['TRAINING']['encoding_dim']), \n",
    "                                                             int(config['DATA']['time_steps']), \n",
    "                                                             int(config['DATA']['features_dim']), \n",
    "                                                             int(config['DATA']['num_classes']))\n",
    "else:\n",
    "    input_dict, output_dict = get_simple_LSTM_encoder(int(config['TRAINING']['encoding_dim']), \n",
    "                                                             int(config['DATA']['time_steps']), \n",
    "                                                             int(config['DATA']['features_dim']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer and losses\n",
    "\n",
    "if classification:\n",
    "    losses_dict = {\n",
    "        'logits': tf.nn.softmax_cross_entropy_with_logits\n",
    "    }\n",
    "else:\n",
    "    losses_dict = {\n",
    "        'encoding': triplet_loss_tf\n",
    "    }\n",
    "\n",
    "if classification:\n",
    "    trainer = ClassificationTrainer(input_dict, output_dict, losses_dict, train_gen_wrap, val_gen_wrap, \n",
    "                     steps_per_epoch_train, steps_per_epoch_val, config_file)\n",
    "else:\n",
    "    trainer = IdentificationTrainer(input_dict, output_dict, losses_dict, train_gen_wrap, val_gen_wrap, \n",
    "                     steps_per_epoch_train, steps_per_epoch_val, config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [?,3840]\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[?,3840], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'Placeholder', defined at:\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/asyncio/base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/asyncio/base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-55-a2db8c7d4c5d>\", line 8, in <module>\n    int(config['DATA']['num_classes']))\n  File \"<ipython-input-54-19a307da4cf6>\", line 76, in get_simple_LSTM_classification\n    input_dict_encoder, output_dict_encoder = get_simple_LSTM_encoder(encoding_dim, n_steps, n_feature_dim)\n  File \"<ipython-input-54-19a307da4cf6>\", line 47, in get_simple_LSTM_encoder\n    x = tf.placeholder(tf.float32, [None, n_steps * n_feature_dim])\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1548, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2094, in _placeholder\n    name=name)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [?,3840]\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[?,3840], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tf13env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf13env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf13env/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf13env/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [?,3840]\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[?,3840], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-9e6c7f4daa93>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, checkpoint)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'print_every'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Step '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' | Training loss: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf13env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf13env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf13env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf13env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [?,3840]\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[?,3840], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'Placeholder', defined at:\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/asyncio/base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/asyncio/base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-55-a2db8c7d4c5d>\", line 8, in <module>\n    int(config['DATA']['num_classes']))\n  File \"<ipython-input-54-19a307da4cf6>\", line 76, in get_simple_LSTM_classification\n    input_dict_encoder, output_dict_encoder = get_simple_LSTM_encoder(encoding_dim, n_steps, n_feature_dim)\n  File \"<ipython-input-54-19a307da4cf6>\", line 47, in get_simple_LSTM_encoder\n    x = tf.placeholder(tf.float32, [None, n_steps * n_feature_dim])\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1548, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2094, in _placeholder\n    name=name)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/janis/anaconda3/envs/tf13env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [?,3840]\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[?,3840], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_cosine_similarity(x1, x2):\n",
    "    \"\"\"\n",
    "    Cosine similarity between x1 and x2\n",
    "    \"\"\"\n",
    "    \n",
    "    dot = K.squeeze(K.batch_dot(x1, x2, axes=1), axis=1)\n",
    "    return dot\n",
    "\n",
    "def batch_cosine_similarity_tf(x1, x2):\n",
    "    \"\"\"\n",
    "    Cosine similarity between x1 and x2\n",
    "    \"\"\"\n",
    "    \n",
    "    dot = tf.einsum('ij,ij->i', x1, x2)\n",
    "    return dot\n",
    "\n",
    "\n",
    "def triplet_loss(y_pred, batch_size, alpha):\n",
    "    \"\"\"\n",
    "    Triplet loss for speaker identification.\n",
    "    \n",
    "    args:\n",
    "        y_pred: contains encoding of anchor, positive and negative sample in this order. -> shape (3*batch_size, ...)\n",
    "    \n",
    "    returns:\n",
    "        total_loss\n",
    "    \"\"\"\n",
    "    \n",
    "    anchor = y_pred[0:batch_size]\n",
    "    positive_ex = y_pred[batch_size:2 * batch_size]\n",
    "    negative_ex = y_pred[2 * batch_size:]\n",
    "    sap = batch_cosine_similarity(anchor, positive_ex)\n",
    "    san = batch_cosine_similarity(anchor, negative_ex)\n",
    "    loss = K.maximum(san - sap + tf.constant(alpha), 0.0)\n",
    "    total_loss = K.mean(loss)\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def triplet_loss_tf(y_pred, batch_size, alpha):\n",
    "    \"\"\"\n",
    "    Triplet loss for speaker identification.\n",
    "    \n",
    "    args:\n",
    "        y_pred: contains encoding of anchor, positive and negative sample in this order. -> shape (3*batch_size, ...)\n",
    "    \n",
    "    returns:\n",
    "        total_loss\n",
    "    \"\"\"\n",
    "    \n",
    "    anchor = y_pred[0:batch_size]\n",
    "    positive_ex = y_pred[batch_size:2 * batch_size]\n",
    "    negative_ex = y_pred[2 * batch_size:]\n",
    "    pos_sim = batch_cosine_similarity(anchor, positive_ex)\n",
    "    neg_sim = batch_cosine_similarity(anchor, negative_ex)\n",
    "    \n",
    "    loss = tf.maximum(neg_sim - pos_sim + tf.constant(alpha), 0.0)\n",
    "    total_loss = tf.reduce_mean(loss)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def LSTM_layer(X, hidden_dim, state_np_init, n_time, return_sequence=False):\n",
    "    \"\"\"\n",
    "    Creates one unidirectional LSTM layer.\n",
    "    \n",
    "    args:\n",
    "        \n",
    "    returns:\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # split operation only support the shape[axis] with integer multiple of 16\n",
    "    X_in = tf.split(X, n_time, 1)\n",
    "    \n",
    "    # define LSTM cell\n",
    "    lstm_cell = tf.contrib.rnn.LSTMCell(hidden_dim)\n",
    "    \n",
    "    # create initial state\n",
    "    cell_state = tf.convert_to_tensor(state_np_init, dtype=tf.float32)\n",
    "    hidden_state = tf.convert_to_tensor(state_np_init, dtype=tf.float32)\n",
    "    state = tf.nn.rnn_cell.LSTMStateTuple(cell_state, hidden_state)\n",
    "    \n",
    "    outputs, states = tf.nn.static_rnn(lstm_cell, X_in, initial_state=state, dtype=tf.float32)\n",
    "    \n",
    "    if return_sequence:\n",
    "        return outputs\n",
    "    else:\n",
    "        return outputs[-1]\n",
    "        \n",
    "\n",
    "def get_simple_LSTM_encoder(encoding_dim: int, n_steps: int, n_feature_dim: int):\n",
    "    \"\"\"\n",
    "    Returns a one layer uni-directional LSTM encoder\n",
    "    \n",
    "    args:\n",
    "        \n",
    "    returns:\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # adapt to huawei dim limitation of multiples of 16\n",
    "    n_steps = n_steps + (n_steps % 16 > 0)*(16 - n_steps % 16)\n",
    "    n_feature_dim = n_feature_dim + (n_feature_dim % 16 > 0)*(16 - n_feature_dim % 16)\n",
    "    \n",
    "    # input\n",
    "    x = tf.placeholder(tf.float32, [None, n_steps * n_feature_dim])\n",
    "    state_np_init = tf.placeholder(tf.float32, [None, encoding_dim])\n",
    "    \n",
    "    # get encoding\n",
    "    with tf.name_scope(\"Encoding\"):\n",
    "        encoding = LSTM_layer(x, encoding_dim, state_np_init, n_steps, )\n",
    "        \n",
    "    input_dict = {\n",
    "        'x': x,\n",
    "        'state': state_np_init\n",
    "    }\n",
    "    \n",
    "    output_dict = {\n",
    "        'encoding': encoding\n",
    "    }\n",
    "    \n",
    "    return input_dict, output_dict\n",
    "\n",
    "def get_simple_LSTM_classification(encoding_dim: int, n_steps: int, n_feature_dim: int, num_classes: int):\n",
    "    \"\"\"\n",
    "    Returns endpoints of classification model.\n",
    "    \n",
    "    args:\n",
    "        \n",
    "    returns:\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # get encoding and model inputs\n",
    "    input_dict_encoder, output_dict_encoder = get_simple_LSTM_encoder(encoding_dim, n_steps, n_feature_dim)\n",
    "    y = tf.placeholder(tf.float32, [None, num_classes])\n",
    "    \n",
    "    logits =  tf.layers.dense(output_dict_encoder['encoding'], num_classes)\n",
    "#     prediction = tf.nn.softmax(logits)\n",
    "    \n",
    "    input_dict = {\n",
    "        'x': input_dict_encoder['x'],\n",
    "        'state': input_dict_encoder['state'],\n",
    "        'y': y\n",
    "    }\n",
    "    \n",
    "    output_dict = {\n",
    "        'logits': logits\n",
    "    }\n",
    "    \n",
    "    return input_dict, output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class BaseTrainer():\n",
    "    \n",
    "    def __init__(self, input_dict, output_dict, losses_dict, train_gen, val_gen, \n",
    "                 steps_per_epoch_train, steps_per_epoch_val, config_file):\n",
    "        \n",
    "        self.input_dict = input_dict\n",
    "        self.output_dict = output_dict\n",
    "        self.losses_dict = losses_dict\n",
    "        self.train_gen = train_gen\n",
    "        self.val_gen = val_gen\n",
    "        self.steps_per_epoch_train = steps_per_epoch_train\n",
    "        self.steps_per_epoch_val = steps_per_epoch_val\n",
    "        \n",
    "        self.params = config['TRAINING']\n",
    "    \n",
    "    \n",
    "    def train(self, checkpoint=None):\n",
    "        \n",
    "        costs = self.compute_loss()\n",
    "\n",
    "        cost = tf.reduce_sum(tf.concat(costs, axis=0))\n",
    "        train_ops = tf.train.AdamOptimizer(float(self.params['lr'])).minimize(cost)\n",
    "        \n",
    "        sess = tf.Session()\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        # create run folder\n",
    "        import datetime\n",
    "        run_folder = 'runs/' + 'tf13' + str(datetime.datetime.now())\n",
    "        writer = tf.summary.FileWriter(run_folder, sess.graph)\n",
    "        \n",
    "        if checkpoint is not None:\n",
    "            saver.restore(sess, checkpoint)\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        best_val_loss = np.inf\n",
    "        patience_counter = 0\n",
    "        for i in range(int(self.params['epochs'])):\n",
    "            print('Epoch ' + str(i))\n",
    "            \n",
    "            train_loss = []\n",
    "            for j in range(self.steps_per_epoch_train):\n",
    "                batch = self.train_gen.__next__()\n",
    "                \n",
    "                inp = self._build_input(batch)\n",
    "                sess.run(train_ops, inp)\n",
    "                \n",
    "                if j % int(self.params['print_every']) == 0:\n",
    "                    train_loss.append(sess.run(train_ops))\n",
    "                    print('Step ' + str(j) + ' | Training loss: ' + str(train_loss[-1]))\n",
    "            \n",
    "            val_loss = []\n",
    "            for j in range(self.steps_per_epoch_val):\n",
    "                batch = self.val_gen.__next__()\n",
    "                inp = self._build_input(batch)\n",
    "                val_loss.append(sess.run(cost, inp))\n",
    "            \n",
    "            val_loss = np.mean(val_loss)\n",
    "            train_loss = np.mean(train_loss)\n",
    "            tf.summary.scalar('train_loss', train_loss)\n",
    "            tf.summary.scalar('val_loss', val_loss)\n",
    "            \n",
    "            print('Epoch ' + str(i) + ' | Training loss: ' + str(train_loss) + ' | Validation loss: ' + str(val_loss))\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= int(self.params['patience']):\n",
    "                    print('Training done!')\n",
    "                    break\n",
    "            \n",
    "                    \n",
    "    def _build_input(self, batch):\n",
    "        inp = {}\n",
    "        for key in self.input_dict.keys():\n",
    "            inp[self.input_dict[key]] = batch[key]\n",
    "        return inp\n",
    "    \n",
    "    def compute_loss(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "\n",
    "class ClassificationTrainer(BaseTrainer):\n",
    "    \n",
    "    def __init__(self, input_dict, output_dict, losses_dict, train_gen, val_gen, \n",
    "                 steps_per_epoch_train, steps_per_epoch_val, config_file):\n",
    "        super(ClassificationTrainer, self).__init__(input_dict, output_dict, losses_dict, train_gen, val_gen, \n",
    "                 steps_per_epoch_train, steps_per_epoch_val, config_file)\n",
    "        \n",
    "    def compute_loss(self):\n",
    "        return tf.reduce_mean(self.losses_dict['logits'](logits=self.output_dict['logits'], \n",
    "                                                         labels=self.input_dict['y']))\n",
    "    \n",
    "    \n",
    "class IdentificationTrainer(BaseTrainer):\n",
    "    \n",
    "    def __init__(self, input_dict, output_dict, losses_dict, train_gen, val_gen, \n",
    "                 steps_per_epoch_train, steps_per_epoch_val, config_file):\n",
    "        super(IdentificationTrainer, self).__init__(input_dict, output_dict, losses_dict, train_gen, val_gen, \n",
    "                 steps_per_epoch_train, steps_per_epoch_val, config_file)\n",
    "        \n",
    "    def compute_loss(self):\n",
    "        return tf.reduce_mean(self.losses_dict['encoding'](self.output_dict['encoding'], \n",
    "                                                          self.params['batch_size'],\n",
    "                                                          self.params['alpha']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "n_time = 80\n",
    "stacked = False\n",
    "bidirectional = False\n",
    "normal = True\n",
    "classification = False\n",
    "\n",
    "def RNN(X, hidden_dim, state_np_init, scope):\n",
    "    # split operation only support the shape[axis] with integer multiple of 16\n",
    "    X_in = tf.split(X, n_time, 1)\n",
    "    lstm_cell = tf.contrib.rnn.LSTMCell(hidden_dim)\n",
    "    cell_state = tf.convert_to_tensor(state_np_init, dtype=tf.float32)\n",
    "    hidden_state = tf.convert_to_tensor(state_np_init, dtype=tf.float32)\n",
    "    state = tf.nn.rnn_cell.LSTMStateTuple(cell_state, hidden_state)\n",
    "    \n",
    "    outputs, states = tf.nn.static_rnn(lstm_cell, X_in, initial_state=state, dtype=tf.float32, scope=scope)\n",
    "    \n",
    "    if scope == 'normal':\n",
    "        return outputs[-1]\n",
    "    else:\n",
    "        return outputs\n",
    "\n",
    "def input_pad_new(x):\n",
    "    return np.pad(x, ((0,0),(0,0),(0,13)), 'constant', constant_values=((0,0),(0,0),(0,0)))\n",
    "\n",
    "# parameters init\n",
    "l_r = 0.001\n",
    "lr = l_r\n",
    "training_iters = 100000\n",
    "\n",
    "# Huawei DDK V150 only support 16 times the n_inputs and n_steps\n",
    "# so the input data of mnist dataset should pad to 32 pixels.\n",
    "n_inputs = 48\n",
    "n_steps = n_time\n",
    "n_hidden_units1 = 48\n",
    "n_hidden_units2 = 64\n",
    "encoding_dim = n_hidden_units2\n",
    "n_classes = num_classes\n",
    "\n",
    "# define placeholder for input\n",
    "x = tf.placeholder(tf.float32, [None, n_steps * n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "# x_reverse = tf.reverse(x, axis=tf.constant([0]))\n",
    "if stacked:\n",
    "    state_np_init1 = tf.placeholder(tf.float32, [None, n_hidden_units1])\n",
    "state_np_init2 = tf.placeholder(tf.float32, [None, n_hidden_units2])\n",
    "\n",
    "# 1. Huawei DDK V150 can't support some operations that use for initialize the state.\n",
    "# 2. to support variable input of num, so add state init as placeholder\n",
    "# state_np_init = tf.placeholder(tf.float32, [None, n_hidden_units])\n",
    "\n",
    "if stacked:\n",
    "    encoding1 = RNN(x, 48, state_np_init1, scope='no')\n",
    "    encoding1 = tf.stack(encoding1, axis=1)\n",
    "    dim = tf.shape(encoding1)[0]\n",
    "    encoding1 = tf.reshape(encoding1, [dim, n_steps*n_inputs])\n",
    "    encoding = RNN(encoding1, 512, state_np_init2, scope='normal')\n",
    "if bidirectional:\n",
    "    encoding1 = RNN(x, n_hidden_units2, state_np_init2, scope='no')\n",
    "    encoding2 = RNN(x_reverse, n_hidden_units2, state_np_init2, scope='reverse')\n",
    "    encoding = tf.add(encoding1, encoding2)\n",
    "if normal:\n",
    "    encoding = RNN(x, n_hidden_units2, state_np_init2, scope='normal')\n",
    "    \n",
    "with tf.name_scope(\"Encoding\"):\n",
    "    encoding = tf.layers.dense(encoding, 512)\n",
    "#     encoding = tf.nn.l2_normalize(encoding, dim=1)\n",
    "\n",
    "# d1 = tf.layers.dense(encoding, 256, activation=tf.nn.relu)\n",
    "logits =  tf.layers.dense(encoding, n_classes)\n",
    "prediction = tf.nn.softmax(logits) \n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=y))\n",
    "train_op = tf.train.AdamOptimizer(l_r).minimize(cost)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))\n",
    "inter = tf.cast(correct_pred,tf.float32)\n",
    "accuracy = tf.reduce_mean(inter)\n",
    "\n",
    "#init session\n",
    "sess = tf.Session()\n",
    "#init all variables\n",
    "\n",
    "#start training\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "import datetime\n",
    "run_folder = 'runs/' + 'tf13' + str(datetime.datetime.now())\n",
    "writer = tf.summary.FileWriter(run_folder, sess.graph)\n",
    "\n",
    "if not classification:\n",
    "    saver.restore(sess, 'runs/60perc_acc_classification/class_ckpt-178')\n",
    "    encoding = tf.nn.l2_normalize(encoding, dim=1)\n",
    "    cost_id = deep_speaker_loss(None, encoding)\n",
    "    train_op_id = tf.train.AdamOptimizer(lr).minimize(cost_id)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    best_val_loss = 100\n",
    "    train_loss = []\n",
    "    all_val_loss = []\n",
    "    patience = 10\n",
    "    for i in range(training_iters):\n",
    "\n",
    "        batch_x, batch_y = gen_train_ident.__next__()\n",
    "        batch_x_pad = input_pad_new(batch_x)\n",
    "        batch_x_pad_reshape = np.reshape(batch_x_pad, [3*batch_size, n_steps*n_inputs])\n",
    "        d = {x: batch_x_pad_reshape, state_np_init2:np.zeros((3*batch_size, n_hidden_units2))}\n",
    "        sess.run(train_op_id,feed_dict=d)\n",
    "#         enc = sess.run(encoding,feed_dict=d)\n",
    "#         print(enc)\n",
    "        if i % 100 == 0:\n",
    "            t_loss = sess.run(cost_id,feed_dict=d)\n",
    "            print(\"Step \" + str(i+1) + \" Training loss: {}\".format(t_loss))\n",
    "            train_loss.append(t_loss)\n",
    "\n",
    "        if i % steps_per_epoch == 0:\n",
    "\n",
    "            val_loss = []\n",
    "            for i in range(validation_steps):\n",
    "                batch_x_val, batch_y_val = gen_val_ident.__next__()\n",
    "                batch_x_pad_val = input_pad_new(batch_x_val)\n",
    "                batch_x_pad_reshape_val = np.reshape(batch_x_pad_val, [3*batch_size, n_steps*n_inputs])\n",
    "                d_v = {x: batch_x_pad_reshape_val, state_np_init2:np.zeros((3*batch_size, n_hidden_units2))}\n",
    "                val_loss.append(sess.run(cost_id,feed_dict=d_v))\n",
    "\n",
    "            t_loss = np.mean(train_loss)\n",
    "            v_loss = np.mean(val_loss)\n",
    "            all_val_loss.append(v_loss)\n",
    "            print(\"Training loss: {}\".format(t_loss))\n",
    "            print(\"Validation loss: {}\".format(v_loss))\n",
    "\n",
    "            tf.summary.scalar('train_loss', t_loss)\n",
    "            tf.summary.scalar('val_loss', v_loss)\n",
    "            train_loss = []\n",
    "\n",
    "            if v_loss < best_val_loss:\n",
    "                best_val_loss = v_loss\n",
    "\n",
    "                saver.save(sess, run_folder + '/mnist_ckpt', i)\n",
    "                output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "                    sess, # The session is used to retrieve the weights\n",
    "                    tf.get_default_graph().as_graph_def(), # The graph_def is used to retrieve the nodes \n",
    "                    [\"Encoding/dense/BiasAdd\"] # The output node names are used to select the usefull nodes\n",
    "                    )\n",
    "\n",
    "                with tf.gfile.GFile(run_folder + '/best_model.pb', \"wb\") as f:\n",
    "                    f.write(output_graph_def.SerializeToString())\n",
    "\n",
    "            if not any(all_val_loss[-patience:] >= best_val_loss):\n",
    "                print('Done!')\n",
    "                break\n",
    "else:\n",
    "    best_val_loss = 100\n",
    "    patience = 10\n",
    "    train_loss = []\n",
    "    all_val_loss = []\n",
    "    for i in range(training_iters):\n",
    "\n",
    "        batch_x, batch_y = gen_train_class.__next__()\n",
    "        batch_x_pad = input_pad_new(batch_x)\n",
    "        batch_x_pad_reshape = np.reshape(batch_x_pad, [batch_size, n_steps*n_inputs])\n",
    "        if stacked:\n",
    "            d = {x: batch_x_pad_reshape, y: batch_y,\n",
    "                                         state_np_init1:np.zeros((batch_size, n_hidden_units1)),\n",
    "                                         state_np_init2:np.zeros((batch_size, n_hidden_units2))}\n",
    "        else:\n",
    "            d = {x: batch_x_pad_reshape, y: batch_y,\n",
    "                                         state_np_init2:np.zeros((batch_size, n_hidden_units2))}\n",
    "        sess.run(train_op,feed_dict=d)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            t_loss = sess.run(cost,feed_dict=d)\n",
    "            print(\"Step \" + str(i+1) + \" Training loss: {}\".format(t_loss))\n",
    "            train_loss.append(t_loss)\n",
    "\n",
    "        if i % steps_per_epoch == 0:\n",
    "\n",
    "            val_loss = []\n",
    "            val_acc = []\n",
    "            for i in range(validation_steps):\n",
    "                batch_x_val, batch_y_val = gen_val_class.__next__()\n",
    "                batch_x_pad_val = input_pad_new(batch_x_val)\n",
    "                batch_x_pad_reshape_val = np.reshape(batch_x_pad_val, [batch_size, n_steps*n_inputs])\n",
    "                if stacked:\n",
    "                    d_v = {x: batch_x_pad_reshape_val, y: batch_y_val,\n",
    "                                             state_np_init1:np.zeros((batch_size, n_hidden_units1)),\n",
    "                                             state_np_init2:np.zeros((batch_size, n_hidden_units2))}\n",
    "                else: \n",
    "                    d_v = {x: batch_x_pad_reshape_val, y: batch_y_val,\n",
    "                                             state_np_init2:np.zeros((batch_size, n_hidden_units2))}\n",
    "\n",
    "                val_loss.append(sess.run(cost,feed_dict=d_v))\n",
    "                val_acc.append(sess.run(accuracy,feed_dict=d_v))\n",
    "\n",
    "            t_loss = np.mean(train_loss)\n",
    "            v_loss = np.mean(val_loss)\n",
    "            v_acc = np.mean(val_acc)\n",
    "            all_val_loss.append(v_loss)\n",
    "            print(\"Training loss: {}\".format(t_loss))\n",
    "            print(\"Validation loss: {}\".format(v_loss))\n",
    "            print(\"Validation accuracy: {}\".format(v_acc))\n",
    "\n",
    "            tf.summary.scalar('train_loss', t_loss)\n",
    "            tf.summary.scalar('val_loss', v_loss)\n",
    "            tf.summary.scalar('val_loss', v_acc)\n",
    "            train_loss = []\n",
    "\n",
    "            if v_loss < best_val_loss:\n",
    "                best_val_loss = v_loss\n",
    "\n",
    "                saver.save(sess, run_folder + '/class_ckpt', i)\n",
    "                output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "                    sess, # The session is used to retrieve the weights\n",
    "                    tf.get_default_graph().as_graph_def(), # The graph_def is used to retrieve the nodes \n",
    "                    [\"Encoding/dense/BiasAdd\"] # The output node names are used to select the usefull nodes\n",
    "                    )\n",
    "\n",
    "                with tf.gfile.GFile(run_folder + '/best_model.pb', \"wb\") as f:\n",
    "                    f.write(output_graph_def.SerializeToString())\n",
    "\n",
    "            if not any(all_val_loss[-patience:] >= best_val_loss):\n",
    "                print('Done!')\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "n_time = 80\n",
    "stacked = False\n",
    "bidirectional = False\n",
    "normal = True\n",
    "\n",
    "def RNN(X, hidden_dim, state_np_init, scope):\n",
    "    # split operation only support the shape[axis] with integer multiple of 16\n",
    "    X_in = tf.split(X, n_time, 1)\n",
    "    lstm_cell = tf.contrib.rnn.LSTMCell(hidden_dim)\n",
    "    cell_state = tf.convert_to_tensor(state_np_init, dtype=tf.float32)\n",
    "    hidden_state = tf.convert_to_tensor(state_np_init, dtype=tf.float32)\n",
    "    state = tf.nn.rnn_cell.LSTMStateTuple(cell_state, hidden_state)\n",
    "    \n",
    "    outputs, states = tf.nn.static_rnn(lstm_cell, X_in, initial_state=state, dtype=tf.float32, scope=scope)\n",
    "    \n",
    "    if scope == 'normal':\n",
    "        return outputs[-1]\n",
    "    else:\n",
    "        return outputs\n",
    "\n",
    "def input_pad_new(x):\n",
    "    return np.pad(x, ((0,0),(0,0),(0,13)), 'constant', constant_values=((0,0),(0,0),(0,0)))\n",
    "\n",
    "# parameters init\n",
    "l_r = 0.001\n",
    "training_iters = 100000\n",
    "\n",
    "# Huawei DDK V150 only support 16 times the n_inputs and n_steps\n",
    "# so the input data of mnist dataset should pad to 32 pixels.\n",
    "n_inputs = 48\n",
    "n_steps = n_time\n",
    "n_hidden_units1 = 48\n",
    "n_hidden_units2 = 512\n",
    "n_classes = num_classes\n",
    "\n",
    "# define placeholder for input\n",
    "x = tf.placeholder(tf.float32, [None, n_steps * n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "# x_reverse = tf.reverse(x, axis=tf.constant([0]))\n",
    "if stacked:\n",
    "    state_np_init1 = tf.placeholder(tf.float32, [None, n_hidden_units1])\n",
    "state_np_init2 = tf.placeholder(tf.float32, [None, n_hidden_units2])\n",
    "\n",
    "# 1. Huawei DDK V150 can't support some operations that use for initialize the state.\n",
    "# 2. to support variable input of num, so add state init as placeholder\n",
    "# state_np_init = tf.placeholder(tf.float32, [None, n_hidden_units])\n",
    "\n",
    "if stacked:\n",
    "    encoding1 = RNN(x, 48, state_np_init1, scope='no')\n",
    "    encoding1 = tf.stack(encoding1, axis=1)\n",
    "    dim = tf.shape(encoding1)[0]\n",
    "    encoding1 = tf.reshape(encoding1, [dim, n_steps*n_inputs])\n",
    "    encoding = RNN(encoding1, 512, state_np_init2, scope='normal')\n",
    "if bidirectional:\n",
    "    encoding1 = RNN(x, n_hidden_units2, state_np_init2, scope='no')\n",
    "    encoding2 = RNN(x_reverse, n_hidden_units2, state_np_init2, scope='reverse')\n",
    "    encoding = tf.add(encoding1, encoding2)\n",
    "if normal:\n",
    "    encoding = RNN(x, n_hidden_units2, state_np_init2, scope='normal')\n",
    "    \n",
    "with tf.name_scope(\"Encoding\"):\n",
    "    encoding = tf.layers.dense(encoding, 512)\n",
    "#     encoding = tf.nn.l2_normalize(encoding, dim=1)\n",
    "\n",
    "# d1 = tf.layers.dense(encoding, 256, activation=tf.nn.relu)\n",
    "logits =  tf.layers.dense(encoding, n_classes)\n",
    "prediction = tf.nn.softmax(logits) \n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=y))\n",
    "train_op = tf.train.AdamOptimizer(l_r).minimize(cost)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))\n",
    "inter = tf.cast(correct_pred,tf.float32)\n",
    "accuracy = tf.reduce_mean(inter)\n",
    "\n",
    "#init session\n",
    "sess = tf.Session()\n",
    "#init all variables\n",
    "sess.run(tf.global_variables_initializer())\n",
    "#start training\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "import datetime\n",
    "run_folder = 'runs/' + 'tf13' + str(datetime.datetime.now())\n",
    "writer = tf.summary.FileWriter(run_folder, sess.graph)\n",
    "\n",
    "best_val_loss = 100\n",
    "patience = 10\n",
    "all_val_loss = []\n",
    "train_loss = []\n",
    "for i in range(training_iters):\n",
    "    \n",
    "    batch_x, batch_y = gen_train_class.__next__()\n",
    "    batch_x_pad = input_pad_new(batch_x)\n",
    "    batch_x_pad_reshape = np.reshape(batch_x_pad, [batch_size, n_steps*n_inputs])\n",
    "    if stacked:\n",
    "        d = {x: batch_x_pad_reshape, y: batch_y,\n",
    "                                     state_np_init1:np.zeros((batch_size, n_hidden_units1)),\n",
    "                                     state_np_init2:np.zeros((batch_size, n_hidden_units2))}\n",
    "    else:\n",
    "        d = {x: batch_x_pad_reshape, y: batch_y,\n",
    "                                     state_np_init2:np.zeros((batch_size, n_hidden_units2))}\n",
    "    sess.run(train_op,feed_dict=d)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        t_loss = sess.run(cost,feed_dict=d)\n",
    "        print(\"Step \" + str(i+1) + \" Training loss: {}\".format(t_loss))\n",
    "        train_loss.append(t_loss)\n",
    "        \n",
    "    if i % steps_per_epoch == 0:\n",
    "        \n",
    "        val_loss = []\n",
    "        val_acc = []\n",
    "        for i in range(validation_steps):\n",
    "            batch_x_val, batch_y_val = gen_val_class.__next__()\n",
    "            batch_x_pad_val = input_pad_new(batch_x_val)\n",
    "            batch_x_pad_reshape_val = np.reshape(batch_x_pad_val, [batch_size, n_steps*n_inputs])\n",
    "            if stacked:\n",
    "                d_v = {x: batch_x_pad_reshape_val, y: batch_y_val,\n",
    "                                         state_np_init1:np.zeros((batch_size, n_hidden_units1)),\n",
    "                                         state_np_init2:np.zeros((batch_size, n_hidden_units2))}\n",
    "            else: \n",
    "                d_v = {x: batch_x_pad_reshape_val, y: batch_y_val,\n",
    "                                         state_np_init2:np.zeros((batch_size, n_hidden_units2))}\n",
    "                \n",
    "            val_loss.append(sess.run(cost,feed_dict=d_v))\n",
    "            val_acc.append(sess.run(accuracy,feed_dict=d_v))\n",
    "            \n",
    "        t_loss = np.mean(train_loss)\n",
    "        v_loss = np.mean(val_loss)\n",
    "        v_acc = np.mean(val_acc)\n",
    "        all_val_loss.append(v_loss)\n",
    "        print(\"Training loss: {}\".format(t_loss))\n",
    "        print(\"Validation loss: {}\".format(v_loss))\n",
    "        print(\"Validation accuracy: {}\".format(v_acc))\n",
    "        \n",
    "        tf.summary.scalar('train_loss', t_loss)\n",
    "        tf.summary.scalar('val_loss', v_loss)\n",
    "        tf.summary.scalar('val_loss', v_acc)\n",
    "        train_loss = []\n",
    "        \n",
    "        if v_loss < best_val_loss:\n",
    "            best_val_loss = v_loss\n",
    "            \n",
    "            saver.save(sess, 'out/mnist_ckpt', i)\n",
    "            output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "                sess, # The session is used to retrieve the weights\n",
    "                tf.get_default_graph().as_graph_def(), # The graph_def is used to retrieve the nodes \n",
    "                [\"Encoding/dense/BiasAdd\"] # The output node names are used to select the usefull nodes\n",
    "            )\n",
    "\n",
    "            with tf.gfile.GFile('out/Encoding_lstm_var_batch.pb', \"wb\") as f:\n",
    "                f.write(output_graph_def.SerializeToString())\n",
    "        \n",
    "        if not any(all_val_loss[-patience:] >= best_val_loss):\n",
    "            print('Done!')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    ### create graph ###\n",
    "    \n",
    "    writer = tf.summary.FileWriter(run_folder, sess.graph)\n",
    "    saver.save(sess, 'out/mnist_ckpt', i)\n",
    "    output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "        sess,\n",
    "        tf.get_default_graph().as_graph_def(), # graph_def\n",
    "        [\"Encoding/dense/BiasAdd\"] # The output node names\n",
    "    )\n",
    "\n",
    "    with tf.gfile.GFile('out/Encoding_lstm_var_batch.pb', \"wb\") as f:\n",
    "        f.write(output_graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def load_graph(frozen_graph_filename):\n",
    "    with tf.gfile.GFile(frozen_graph_filename, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(\n",
    "            graph_def, \n",
    "            input_map=None, \n",
    "            return_elements=None, \n",
    "            name=\"prefix\", \n",
    "            op_dict=None, \n",
    "            producer_op_list=None\n",
    "        )\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = load_graph('Encoding_lstm_var_batch_class.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get operation and tensor names for later reference\n",
    "for op in graph.get_operations():\n",
    "    print(op.name)\n",
    "    print(op.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_train_ident = data_generator_identification(train_files, batch_size, steps_per_epoch, mode='train', model='LSTM')\n",
    "gen_val_ident = data_generator_identification(val_files, batch_size, validation_steps, mode='val', model='LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "def batch_cosine_similarity(x1, x2):\n",
    "    # https://en.wikipedia.org/wiki/Cosine_similarity\n",
    "    # 1 = equal direction ; -1 = opposite direction\n",
    "    dot = K.squeeze(K.batch_dot(x1, x2, axes=1), axis=1)\n",
    "    logging.info('dot: {}'.format(dot))\n",
    "    # as values have have length 1, we don't need to divide by norm (as it is 1)\n",
    "    return dot\n",
    "\n",
    "\n",
    "def deep_speaker_loss(y_true, y_pred):\n",
    "    logging.info('y_true={}'.format(y_true))\n",
    "    logging.info('y_pred={}'.format(y_pred))\n",
    "    # y_true.shape = (batch_size, embedding_size)\n",
    "    # y_pred.shape = (batch_size, embedding_size)\n",
    "    # CONVENTION: Input is:\n",
    "    # concat(BATCH_SIZE * [ANCHOR, POSITIVE_EX, NEGATIVE_EX] * NUM_FRAMES)\n",
    "    # EXAMPLE:\n",
    "    # BATCH_NUM_TRIPLETS = 3, NUM_FRAMES = 2\n",
    "    # _____________________________________________________\n",
    "    # ANCHOR 1 (512,)\n",
    "    # ANCHOR 2 (512,)\n",
    "    # ANCHOR 3 (512,)\n",
    "    # POS EX 1 (512,)\n",
    "    # POS EX 2 (512,)\n",
    "    # POS EX 3 (512,)\n",
    "    # NEG EX 1 (512,)\n",
    "    # NEG EX 2 (512,)\n",
    "    # NEG EX 3 (512,)\n",
    "    # _____________________________________________________\n",
    "\n",
    "    logging.info('elements={}'.format(batch_size))\n",
    "    anchor = y_pred[0:batch_size]\n",
    "    positive_ex = y_pred[batch_size:2*batch_size]\n",
    "    negative_ex = y_pred[2*batch_size:]\n",
    "    \n",
    "    logging.info('anchor={}'.format(anchor))\n",
    "    logging.info('positive_ex={}'.format(positive_ex))\n",
    "    logging.info('negative_ex={}'.format(negative_ex))\n",
    "\n",
    "    sap = batch_cosine_similarity(anchor, positive_ex)\n",
    "    logging.info('sap={}'.format(sap))\n",
    "    san = batch_cosine_similarity(anchor, negative_ex)\n",
    "    logging.info('san={}'.format(san))\n",
    "    loss = K.maximum(san - sap + alpha, 0.0)\n",
    "    logging.info('loss={}'.format(loss))\n",
    "    # total_loss = K.sum(loss)\n",
    "#     total_loss = K.mean(loss)\n",
    "#     logging.info('total_loss={}'.format(total_loss))\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph2 = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "\n",
    "# access the input and output nodes via tensor names\n",
    "x = graph.get_tensor_by_name('prefix/Placeholder:0')\n",
    "state = graph.get_tensor_by_name('prefix/Placeholder_2:0')\n",
    "encoding = graph.get_tensor_by_name('prefix/Encoding/dense/BiasAdd:0')\n",
    "\n",
    "with tf.Session(graph=graph):\n",
    "    cost = deep_speaker_loss(None, encoding)\n",
    "#     train_op = tf.train.AdamOptimizer(lr).minimize(cost)\n",
    "    tf_saver = tf.train.Saver()\n",
    "    tf_saver.restore(sess, 'out/mnist_ckpt-345')\n",
    "    print(train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "import datetime\n",
    "\n",
    "run_folder = 'runs/' + str(datetime.datetime.now())\n",
    "\n",
    "os.mkdir(run_folder)\n",
    "\n",
    "class_model.fit_generator(gen_train_class, \n",
    "                steps_per_epoch=steps_per_epoch, \n",
    "                epochs=epochs,\n",
    "                validation_data=gen_val_class, \n",
    "                validation_steps=validation_steps,\n",
    "                callbacks=[\n",
    "                    ModelCheckpoint(run_folder + '/best_model.hdf5', save_best_only=True),\n",
    "                    EarlyStopping(patience=10),\n",
    "                    TensorBoard(log_dir=run_folder)\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_model.load_weights(run_folder + '/' + 'best_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dat = np.zeros((10*batch_size, 80, 35, 1))\n",
    "val_dat_t = np.zeros((10*batch_size, 165))\n",
    "for i in range(10):\n",
    "    d, t = gen_val_class.__next__()\n",
    "    val_dat[i*batch_size:(i+1)*batch_size] = d\n",
    "    val_dat_t[i*batch_size:(i+1)*batch_size] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = class_model.predict(val_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am = np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at = np.argmax(val_dat_t, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(at == am).sum()/len(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_model.save_weights('triplet_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_model.load_weights('triplet_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = \"\"\n",
    "        frozen_graph = convert_variables_to_constants(session, input_graph_def,\n",
    "                                                      output_names, freeze_var_names)\n",
    "        return frozen_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze graph for storing it\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "frozen_graph = freeze_session(K.get_session(), output_names=[out.op.name for out in triplet_model.outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save graph as .pb\n",
    "tf.train.write_graph(frozen_graph, \"\", \"triplet_model.pb\", as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
